#!/usr/bin/env python3

from __future__ import annotations

import argparse
import logging
import re
import subprocess
from abc import ABC, abstractmethod
from dataclasses import dataclass
from functools import cached_property
from os import getenv
from pathlib import Path
from textwrap import dedent
from typing import Callable, Dict, List, Optional, Type

import tomllib

logging.basicConfig(format="%(levelname)s: %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    base_dir: Path
    ignore_dirs: List[str]
    infra_jobs: List[str]
    job_configs: List[str]
    filters: Dict[str, Dict]

    @classmethod
    def from_toml(cls, config_path: Path) -> Config:
        if not config_path.exists():
            cls.create_default(config_path)

        try:
            with config_path.open("rb") as f:
                data = tomllib.load(f)
        except tomllib.TOMLDecodeError as e:
            raise RuntimeError(f"Invalid TOML syntax: {e}")

        general_cfg = data.get("general", {})
        return cls(
            base_dir=Path(general_cfg.get("base_dir", "")).expanduser(),
            ignore_dirs=general_cfg.get("ignore_dirs", []),
            infra_jobs=general_cfg.get("infra_jobs", []),
            job_configs=general_cfg.get("job_configs", []),
            filters=data.get("filter", {}),
        )

    @staticmethod
    def create_default(config_path: Path) -> None:
        config = dedent(
            """\
            # Default configuration for nmgr

            [general]

            # Base directory containing Nomad jobs
            base_dir = "~/cld"

            # Directories to ignore when scanning for jobs
            ignore_dirs = ["_archive", ".github", ".git"]

            # Infrastructure jobs to treat with more care (e.g., not auto-restart)
            infra_jobs = ["garage", "keydb", "haproxy", "caddy", "patroni"]

            # File patterns considered as job configs
            job_configs = [
                "*.env*", "*.toml*", "*.yml*", "*.yaml*",
                "*.sh*", "*.cfg*", "*.js*", "*.tpl"
            ]

            # Custom job filters
            # [filter]

            # Example: jobs containing "/mnt/nas" in its spec
            # nas.keywords = ["/mnt/nas"]
            # Example: jobs containing "/mnt/jfs" in its spec
            # jfs.keywords = ["/mnt/jfs"]

            # Example: jobs containing "15432" in its spec or accompanying config files, including infra jobs
            # [filter.db]
            # keywords = ["15432"]
            # extended_search = true
            # exclude_infra = false
            """
        )

        config_path.parent.mkdir(parents=True, exist_ok=True)
        config_path.write_text(config, encoding="utf-8")
        logger.info(f"Generated default config at {config_path}")


@dataclass
class NomadJob:
    name: str
    spec_path: Path
    config_paths: List[Path]

    @cached_property
    def spec(self) -> str:
        return self.spec_path.read_text()

    @cached_property
    def configs(self) -> str:
        configs = []
        for path in self.config_paths:
            try:
                configs.append(path.read_text())
            except Exception as e:
                logger.warning(f"Error reading {path}: {str(e)}")
        return "\n".join(configs)


class Action(ABC):
    """Abstract base class for handling user-requested action on Nomad jobs"""

    _registry: Dict[str, Type[Action]] = {}

    def __init__(self, nomad: NomadClient, config: Config):
        self.nomad = nomad
        self.config = config

    @classmethod
    def register(cls, action: str) -> Callable[[Type[Action]], Type[Action]]:
        def decorator(subcls: Type[Action]) -> Type[Action]:
            cls._registry[action] = subcls
            return subcls

        return decorator

    @classmethod
    def get(cls, action: str, nomad: NomadClient, config: Config) -> Action:
        try:
            handler_cls = cls._registry[action]
        except KeyError:
            raise ValueError(f"Unknown action: {action}")
        return handler_cls(nomad, config)

    @abstractmethod
    def handle(self, jobs: List[NomadJob]) -> None:
        pass


@Action.register("up")
class UpAction(Action):
    """Runs job if not running or spec has changed"""

    def handle(self, jobs: List[NomadJob]) -> None:
        for job in jobs:
            if self.nomad.is_running(job.name):
                logger.debug(f"Job {job.name} is already running; skipping")
                continue

            logger.debug(f"Bringing job UP: {job.name}")
            self.nomad.run_job(job)


@Action.register("down")
class DownAction(Action):
    """Stops and purges job if running"""

    def handle(self, jobs: List[NomadJob]) -> None:
        for job in jobs:
            if not self.nomad.is_running(job.name):
                logger.debug(f"Job {job.name} is not running; skipping")
                continue

            logger.debug(f"Bringing job DOWN: {job.name}")
            self.nomad.stop_job(job.name)


@Action.register("list")
@Action.register("find")
class ListAction(Action):
    """Lists jobs"""

    def handle(self, jobs: List[NomadJob]) -> None:
        for job in jobs:
            print(job.name)


@Action.register("image")
class ImageAction(Action):
    """Prints container image information for job"""

    def handle(self, jobs: List[NomadJob]) -> None:
        for job in jobs:
            live = self.nomad.get_live_image(job.name)
            spec = self.nomad.get_spec_image(job.spec)
            print(f"Live images:\n{live}\n\nSpec images:\n{spec}")


@Action.register("logs")
class LogsAction(Action):
    """Tails the logs for a given task in a job"""

    def handle(self, jobs: List[NomadJob]) -> None:
        if len(jobs) > 1:
            logger.error("Logs cannot be supplied for more than one job at a time")
            return

        job = jobs[0]
        tasks = self.nomad._extract_tasks(job.name)

        if len(tasks) == 1:
            # Auto-select the only task
            task = tasks[0]
        else:
            print(f"Tasks for job {job.name}:")
            for i, opt in enumerate(tasks, start=1):
                print(f"{i}. {opt}")

            while True:
                choice = input("\nSelect a task (number): ").strip()
                if choice.isdigit() or 1 <= int(choice) <= len(tasks):
                    task = tasks[int(choice) - 1]
                    break
                print("Invalid input; please enter a valid number")

        self.nomad.tail_logs(task_name=task, job_name=job.name)


@Action.register("reconcile")
class ReconcileAction(Action):
    """Restarts job if spec contains new image"""

    def handle(self, jobs: List[NomadJob]) -> None:
        for job in jobs:
            if not self.nomad.is_running(job.name):
                logger.debug(f"Job {job.name} is not running; skipping")
                continue

            live_image = self.nomad.get_live_image(job.name)
            spec_image = self.nomad.get_spec_image(job.spec)

            logger.debug(f"Live images:\n{live_image}")
            logger.debug(f"Spec images:\n{spec_image}")

            if live_image == spec_image:
                logger.debug(f"No changes for {job.name}; skipping")
                continue

            # Skip (likely critical) infrastucture jobs by default
            if job.name in self.config.infra_jobs:
                logger.info(f"Skipping infra job: {job.name}")
                continue

            logger.info(f"Reconciling job {job.name}: image changed. Restarting...")
            self.nomad.run_job(job)


class Filter(ABC):
    """Abstract base class for filtering Nomad jobs by user-requested target"""

    _registry: Dict[str, Type[Filter]] = {}

    @classmethod
    def register(cls, target: str) -> Callable[[Type[Filter]], Type[Filter]]:
        def decorator(subcls: Type[Filter]) -> Type[Filter]:
            cls._registry[target] = subcls
            return subcls

        return decorator

    @classmethod
    def get(cls, target: str, config: Config) -> Filter:
        # 1) Built-in filter?
        if target in cls._registry:
            logger.debug(f"Target '{target}' matches built-in filter")
            return cls._registry[target]()

        # 2) Config-defined filter?
        if target in config.filters:
            logger.debug(f"Target '{target}' matches config-defined filter")
            filter_cfg = config.filters[target]
            return ContentFilter(
                keywords=filter_cfg.get("keywords", []),
                extended_search=filter_cfg.get("extended_search", False),
                exclude_infra=filter_cfg.get("exclude_infra", True),
            )

        # 3) Fallback: assume target as a job name
        logger.debug(f"Target '{target}' not matching any filter, treating as job name")
        return NameFilter(target)

    @abstractmethod
    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        pass


@Filter.register("infra")
class InfraFilter(Filter):
    """Returns infrastructure jobs, respecting their order in config"""

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        ordered = []
        for infra_name in config.infra_jobs:
            for job in jobs:
                if job.name == infra_name:
                    ordered.append(job)
        return ordered


@Filter.register("services")
class ServicesFilter(Filter):
    """Returns service (i.e. non-infrastructure) jobs"""

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        return [job for job in jobs if job.name not in config.infra_jobs]


@Filter.register("all")
class AllFilter(Filter):
    """Returns both infra and services jobs, always ordering infra jobs first"""

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        infra = InfraFilter().filter(jobs, config)
        services = ServicesFilter().filter(jobs, config)
        return infra + services


class NameFilter(Filter):
    """Fallback filter that returns job matching a single specific name"""

    def __init__(self, name: str):
        self.name = name

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        return [job for job in jobs if job.name == self.name]


class ContentFilter(Filter):
    """Parametric filter for searching job specs and accompanying configs"""

    def __init__(
        self,
        keywords: List[str],
        extended_search: bool = False,
        exclude_infra: bool = True,
    ):
        self.keywords = keywords
        self.extended_search = extended_search
        self.exclude_infra = exclude_infra

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        matched = []
        for job in jobs:
            text = job.spec + job.configs if self.extended_search else job.spec
            if any(keyword in text for keyword in self.keywords):
                if self.exclude_infra and job.name in config.infra_jobs:
                    continue
                matched.append(job)
        return matched


class JobRegistrar:
    """Locates and registers Nomad job specs and accompanying config files"""

    def __init__(self, config: Config):
        self.config = config

    def find_jobs(self) -> List[NomadJob]:
        jobs = []
        for path in self.config.base_dir.iterdir():
            if not path.is_dir() or path.name in self.config.ignore_dirs:
                logger.debug(f"Skipping: {path}")
                continue

            for spec_file in path.glob("*.hcl"):
                try:
                    jobs.append(self._register_job(spec_file))
                except ValueError as e:
                    logger.warning(f"Failed to load {spec_file}: {e}")
        return jobs

    def _register_job(self, spec_path: Path) -> NomadJob:
        return NomadJob(
            name=self._extract_job_name(spec_path),
            spec_path=spec_path,
            config_paths=self._find_configs(spec_path.parent),
        )

    def _find_configs(self, directory: Path) -> List[Path]:
        configs = []
        for pattern in self.config.job_configs:
            configs.extend(directory.glob(pattern))
        return [config for config in configs if config.is_file()]

    @staticmethod
    def _extract_job_name(spec_path: Path) -> str:
        """Scans for "foo" in lines such as: 'job "foo"'"""
        with spec_path.open() as f:
            for line in f:
                match = re.search(r'job\s+"([^"]+)"', line)
                if match:
                    return match.group(1)
        raise ValueError("Missing job name in spec")


class NomadClient:
    """Wraps interactions with the Nomad CLI"""

    def __init__(self, config: Config, dry_run: bool = False, detach: bool = False):
        self.config = config
        self.dry_run = dry_run
        self.detach = detach

    def run_job(self, job: NomadJob) -> None:
        cmd = ["nomad", "run"]
        # Skip detach on infra jobs to let Nomad declare them healthy before proceeding
        if self.detach and job.name not in self.config.infra_jobs:
            cmd.append("-detach")
        cmd.append(job.spec_path.name)

        self._execute(cmd, cwd=str(job.spec_path.parent))
        logger.debug(f"Started job: {job.name}")

    def stop_job(self, job_name: str) -> None:
        self._execute(["nomad", "stop", "-purge", job_name])
        logger.debug(f"Stopped job: {job_name}")

    def is_running(self, job_name: str) -> bool:
        result = self._execute(
            # TODO: check `nomad job status -json` instead
            ["nomad", "job", "status", "-short", job_name],
            check=False,
            capture_output=True,
        )
        # Check whether line containing "Status" ends with "running"
        status_line = [line for line in result.stdout.splitlines() if "Status" in line]
        if not status_line:
            return False
        return status_line[0].split()[-1].lower() == "running"

    def tail_logs(self, task_name: str, job_name: str) -> None:
        self._execute(["nomad", "logs", "-f", "-task", task_name, "-job", job_name])

    def inspect_job(self, job_name: str) -> str:
        try:
            result = self._execute(
                ["nomad", "job", "inspect", "-hcl", job_name], capture_output=True
            )
            return result.stdout
        except subprocess.CalledProcessError as e:
            logger.error(f"Error inspecting job {job_name}: {e.stderr}")
            return ""

    def get_live_image(self, job_name: str) -> str:
        live_spec = self.inspect_job(job_name)
        return self._extract_images(live_spec)

    def get_spec_image(self, spec: str) -> str:
        return self._extract_images(spec)

    def _extract_tasks(self, job_name: str) -> List[str]:
        live_spec = self.inspect_job(job_name)
        matches = re.findall(r'task\s+"([^"]+)"', live_spec)
        if matches:
            return matches
        logger.warning(f"No tasks found for job: {job_name}")
        return []

    @staticmethod
    def _extract_images(spec: str) -> str:
        # TODO: return sorted lists instead of raw strings
        """
        Scans for lines such as
            image = "foo/bar"
        or the content of blocks such as:
            image = {
              kutt = "docker.io/kutt/kutt:v3.2.2"
              valkey = "docker.io/valkey/valkey:8.0-alpine"
            }
        """

        pattern = re.compile(r'image\s*=\s*(".*?"|\{[^}]*\})', re.DOTALL)
        matches = pattern.findall(spec)

        results = []

        for match in matches:
            if "local." in match:
                continue  # skip HCL variable references

            match = match.strip()
            # Extract only content of blocks and split by line
            if match.startswith("{") and match.endswith("}"):
                content = match[1:-1].strip()  # remove surrounding brackets
                for line in content.splitlines():
                    line = line.strip()
                    if line:
                        results.append(line)
            else:
                results.append(match)

        return "\n".join(results)

    def _execute(
        self,
        cmd: List[str],
        cwd: Optional[str] = None,
        check: bool = True,
        capture_output: bool = False,
    ) -> subprocess.CompletedProcess[str]:
        cmd_str = " ".join(cmd)
        logger.debug(f"Executing command: {cmd_str}" + (f" (cwd={cwd})" if cwd else ""))

        # For commands that modify state, honor dry_run
        if self.dry_run and not capture_output:
            logger.info("[DRY RUN] %s", " ".join(cmd))
            return subprocess.CompletedProcess(cmd, returncode=0, stdout="", stderr="")

        try:
            return subprocess.run(
                cmd, check=check, text=True, cwd=cwd, capture_output=capture_output
            )
        except subprocess.CalledProcessError as e:
            logger.error(f"Command failed: {cmd_str}\nError: {e.stderr}")
            raise


class App:
    """Orchestrates the program flow"""

    def __init__(
        self,
        args: argparse.Namespace,
        config: Config,
        nomad: NomadClient,
        registrar: JobRegistrar,
    ):
        self.args = args
        self.config = config
        self.registrar = registrar
        self.nomad = nomad

    def run(self) -> None:
        all_jobs = self.registrar.find_jobs()
        if not all_jobs:
            logger.warning("No jobs found")
            return

        if self.args.action == "find":
            target = ContentFilter(
                keywords=[self.args.target],
                extended_search=False,
                exclude_infra=False,
            )  # TODO: don't hard-code extended search
        else:
            target = Filter.get(self.args.target, self.config)

        jobs = target.filter(all_jobs, self.config)
        if not jobs:
            logger.warning(f"No jobs found matching target: {self.args.target}")
            return

        try:
            action = Action.get(self.args.action, self.nomad, self.config)
        except ValueError as e:
            logger.error(e)
            return

        action.handle(jobs)


def generate_completion() -> None:
    data_dir = getenv("XDG_DATA_HOME") or Path.home() / ".local" / "share"
    script_path = Path(data_dir) / "bash-completion" / "completions" / "nmgr"

    script_path.parent.mkdir(parents=True, exist_ok=True)
    script = dedent(
        """\
        #!/bin/bash

        _nmgr_completions() {
            local cur cword actions targets jobs words
            _init_completion || return

            if [[ $cur == -* ]]; then
                options="$(nmgr --list-options)"
                mapfile -t COMPREPLY < <(compgen -W "$options" -- "$cur")
                return
            fi

            local arg_count=0
            for word in "${words[@]:1:$((cword - 1))}"; do
                if [[ $word != -* ]]; then
                    ((arg_count++))
                fi
            done

            case $arg_count in
                0)
                    actions="$(nmgr --list-actions)"
                    mapfile -t COMPREPLY < <(compgen -W "$actions" -- "$cur")
                    ;;
                1)
                    targets="$(nmgr --list-targets | sort)"
                    jobs="$(nmgr list all | sort)"
                    mapfile -t COMPREPLY < <(compgen -W "$targets $jobs" -- "$cur")
                    ;;
            esac
        }

        complete -o nosort -F _nmgr_completions nmgr
        """
    )

    if script_path.exists():
        existing_content = script_path.read_text(encoding="utf-8")
        if existing_content.strip() == script.strip():
            print(f"Completion script is already up-to-date at {script_path}")
            return
        else:
            print(f"Updating completion script at {script_path}")

    script_path.write_text(script, encoding="utf-8")
    script_path.chmod(0o755)
    logger.info("Bash completion script installed at {script_path}")


def main() -> None:
    actions = Action._registry.keys()
    targets = Filter._registry.keys()
    config_dir = getenv("XDG_CONFIG_HOME") or Path.home() / ".config"
    config_path = Path(config_dir) / "nmgr" / "config.toml"

    parser = argparse.ArgumentParser(
        description="Nomad job manager",
        usage="%(prog)s [options] [action] [target]",
    )
    parser.add_argument(
        "action",
        nargs="?",
        help=f"{', '.join(actions)}",
    )
    parser.add_argument(
        "target",
        nargs="?",
        help=f'{", ".join(targets)}, a custom filter, a specific job name, or a string (for the "find" action)',
    )
    parser.add_argument(
        "-c",
        "--config",
        default=config_path,
        type=Path,
        help=f"path to config file (default: {config_path})",
    )
    parser.add_argument("-n", "--dry-run", action="store_true", help="dry-run mode")
    parser.add_argument(
        "-d", "--detach", action="store_true", help="start jobs in detached mode"
    )
    parser.add_argument("-v", "--verbose", action="store_true", help="verbose output")
    parser.add_argument(
        "--completion",
        action="store_true",
        help="install autocompletion for Bash and exit",
    )
    # Bash-completion helpers
    parser.add_argument("--list-actions", action="store_true", help=argparse.SUPPRESS)
    parser.add_argument("--list-targets", action="store_true", help=argparse.SUPPRESS)
    parser.add_argument("--list-options", action="store_true", help=argparse.SUPPRESS)

    args = parser.parse_args()

    if args.list_actions:
        print("\n".join(actions))
        exit(0)
    if args.list_targets:
        print("\n".join(targets))
        exit(0)
    if args.list_options:
        options = []
        for action in parser._actions:
            options.extend(action.option_strings)
        print("\n".join(sorted(set(options))))
        exit(0)
    if args.completion:
        generate_completion()
        exit(0)

    if args.verbose:
        logger.setLevel(logging.DEBUG)

    try:
        config = Config.from_toml(args.config)
    except Exception as e:
        logger.error(f"Failed to load config: {e}")
        exit(1)

    try:
        nomad = NomadClient(config, args.dry_run, args.detach)
        registrar = JobRegistrar(config)
        app = App(args, config, nomad, registrar)
        app.run()
    except KeyboardInterrupt:
        logger.info("Interrupted")
        exit(0)
    except Exception as e:
        logger.error(f"Operation failed: {e}")
        exit(1)


if __name__ == "__main__":
    main()
