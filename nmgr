#!/usr/bin/env python3

from __future__ import annotations

import argparse
import logging
import re
import subprocess
from abc import ABC, abstractmethod
from dataclasses import dataclass
from functools import cached_property
from pathlib import Path
from typing import Callable, Dict, List, Type

logging.basicConfig(format="%(levelname)s: %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    base_dir: Path
    ignore_dirs: List[str]
    infra_jobs: List[str]


@dataclass
class NomadJob:
    name: str
    spec_path: Path
    config_paths: List[Path]

    @cached_property
    def spec(self) -> str:
        return self.spec_path.read_text()

    @cached_property
    def configs(self) -> str:
        configs = []
        for path in self.config_paths:
            try:
                configs.append(path.read_text())
            except Exception as e:
                logger.warning(f"Error reading {path}: {str(e)}")
        return "\n".join(configs)


class ActionHandler(ABC):
    """Abstract base class for handling user-requested action on Nomad jobs"""

    _registry: Dict[str, Type[ActionHandler]] = {}

    def __init__(self, nomad: NomadClient, config: Config):
        self.nomad = nomad
        self.config = config

    @classmethod
    def register(
        cls, action: str
    ) -> Callable[[Type[ActionHandler]], Type[ActionHandler]]:
        def decorator(subcls: Type[ActionHandler]) -> Type[ActionHandler]:
            cls._registry[action] = subcls
            return subcls

        return decorator

    @classmethod
    def get(cls, action: str, nomad: NomadClient, config: Config) -> ActionHandler:
        try:
            handler_cls = cls._registry[action]
        except KeyError:
            raise ValueError(f"Unknown action: {action}")
        return handler_cls(nomad, config)

    @abstractmethod
    def handle(self, jobs: List[NomadJob]):
        pass


@ActionHandler.register("up")
class UpHandler(ActionHandler):
    """Runs a job if not running or spec has changed"""

    def handle(self, jobs: List[NomadJob]):
        for job in jobs:
            if self.nomad.is_running(job):
                logger.debug(f"Job {job.name} is already running; skipping")
                continue

            logger.debug(f"Bringing job UP: {job.name}")
            self.nomad.run_job(job)


@ActionHandler.register("down")
class DownHandler(ActionHandler):
    """Stops and purges a job if running"""

    def handle(self, jobs: List[NomadJob]):
        for job in jobs:
            if not self.nomad.is_running(job):
                logger.debug(f"Job {job.name} is not running; skipping")
                continue

            logger.debug(f"Bringing job DOWN: {job.name}")
            self.nomad.stop_job(job)


@ActionHandler.register("reconcile")
class ReconcileHandler(ActionHandler):
    """Restarts job if spec contains new image"""

    def handle(self, jobs: List[NomadJob]):
        for job in jobs:
            if not self.nomad.is_running(job):
                logger.debug(f"Job {job.name} is not running; skipping")
                continue

            live_image = self._get_live_image(job)
            spec_image = self._get_spec_image(job)

            logger.debug(f"Live image: {live_image}")
            logger.debug(f"Spec image: {spec_image}")

            if live_image == spec_image:
                logger.debug(f"No changes for {job.name}; skipping")
                continue

            # Skip (likely critical) infrastucture jobs by default
            if job.name in self.config.infra_jobs:
                logger.info(f"Skipping infra job: {job.name}")
                continue

            logger.info(f"Reconciling job {job.name}: image changed. Restarting...")
            self.nomad.run_job(job)

    def _get_live_image(self, job: NomadJob) -> str:
        try:
            result = subprocess.run(
                ["nomad", "job", "inspect", "-hcl", job.name],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=True,
            )
            return self._extract_images(result.stdout)
        except subprocess.CalledProcessError as e:
            logger.error(f"Error inspecting job {job.name}: {e.stderr}")
            return ""

    def _get_spec_image(self, job: NomadJob) -> str:
        return self._extract_images(job.spec)

    def _extract_images(self, spec: str) -> str:
        """
        Scans for lines such as 'image = "foo/bar"' or the contents of blocks such as:
            image = {
              kutt = "docker.io/kutt/kutt:v3.2.2"
              valkey = "docker.io/valkey/valkey:8.0-alpine"
            }
        """
        pattern = re.compile(r'image\s*=\s*(".*?"|\{[^}]*\})', re.DOTALL)
        images = pattern.findall(spec)
        filtered = [
            re.sub(r"\s+", " ", img.strip())
            for img in images
            if "local.image" not in img  # skip HCL variable references
        ]
        return "\n".join(filtered) if filtered else ""


class TargetFilter(ABC):
    """Abstract base class for filtering Nomad jobs by user-requested target"""

    _registry: Dict[str, Type[TargetFilter]] = {}

    @classmethod
    def register(
        cls, target: str
    ) -> Callable[[Type[TargetFilter]], Type[TargetFilter]]:
        def decorator(subcls: Type[TargetFilter]) -> Type[TargetFilter]:
            cls._registry[target] = subcls
            return subcls

        return decorator

    @classmethod
    def get(cls, target: str) -> TargetFilter:
        filter_cls = cls._registry.get(target)
        if filter_cls is not None:
            return filter_cls()
        # If user-requested target is not in registry, assume it's a job name
        return NameFilter(target)

    @abstractmethod
    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        pass


@TargetFilter.register("infra")
class InfraFilter(TargetFilter):
    """Returns infrastructure jobs, respecting their order in config.infra_jobs"""

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        ordered = []
        for infra_name in config.infra_jobs:
            for job in jobs:
                if job.name == infra_name:
                    ordered.append(job)
        return ordered


@TargetFilter.register("services")
class ServicesFilter(TargetFilter):
    """Returns service (i.e. non-infrastructure) jobs"""

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        return [job for job in jobs if job.name not in config.infra_jobs]


@TargetFilter.register("all")
class AllFilter(TargetFilter):
    """Returns both infra and services jobs, always ordering infra jobs first"""

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        infra = InfraFilter().filter(jobs, config)
        services = ServicesFilter().filter(jobs, config)
        return infra + services


class NameFilter(TargetFilter):
    """Fallback filter that returns job matching a single specific name"""

    def __init__(self, name: str):
        self.name = name

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        return [job for job in jobs if job.name == self.name]


class ContentFilter(TargetFilter):
    """Base class for returning jobs whose spec or configs contain the specified keywords"""

    keywords: List[str] = []
    extended_search: bool = False

    def filter(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        matched = []
        for job in jobs:
            text = (job.spec + job.configs) if self.extended_search else job.spec
            if (
                any(keyword in text for keyword in self.keywords)
                and job.name not in config.infra_jobs
            ):
                matched.append(job)
        return matched


@TargetFilter.register("db")
class DBFilter(ContentFilter):
    keywords = ["15432"]
    extended_search = True


@TargetFilter.register("nas")
class NASFilter(ContentFilter):
    keywords = ["/mnt/nas"]


@TargetFilter.register("jfs")
class JFSFilter(ContentFilter):
    keywords = ["/mnt/jfs"]


@TargetFilter.register("crypt")
class CryptFilter(ContentFilter):
    keywords = ["/mnt/crypt"]


class JobRegistry:
    """Finds and registers Nomad jobs along with their surrounding config files"""

    def __init__(self, config: Config, job_cfg_globs: List[str] = []):
        self.config = config
        # TODO: poor variable naming
        self.job_cfg_globs = job_cfg_globs or [
            "*.env*",
            "*.toml*",
            "*.yml*",
            "*.yaml*",
            "*.sh*",
            "*.cfg*",
            "*.js*",
            "*.tpl",
        ]

    def find_jobs(self) -> List[NomadJob]:
        jobs = []
        for path in self.config.base_dir.iterdir():
            if not path.is_dir() or path.name in self.config.ignore_dirs:
                logger.debug(f"Skipping: {path}")
                continue

            for spec_path in path.glob("*.hcl"):
                try:
                    jobs.append(self._register_job(spec_path))
                except ValueError as e:
                    logger.warning(f"Failed to load {spec_path}: {e}")
        return jobs

    def _register_job(self, spec_path: Path) -> NomadJob:
        return NomadJob(
            name=self._extract_job_name(spec_path),
            spec_path=spec_path,
            config_paths=self._find_configs(spec_path.parent),
        )

    def _find_configs(self, directory: Path) -> List[Path]:
        configs = []
        for pattern in self.job_cfg_globs:
            for path in directory.glob(pattern):
                if path.is_file():
                    configs.append(path)
        return configs

    @staticmethod
    def _extract_job_name(spec_path: Path) -> str:
        """Scans for "foo" in lines such as: 'job "foo"'"""
        with spec_path.open() as f:
            for line in f:
                match = re.search(r'job\s+"([^"]+)"', line)
                if match:
                    return match.group(1)
        raise ValueError("Missing job name in spec")


class NomadClient:
    """Wraps interactions with the Nomad CLI"""

    def __init__(self, config: Config, dry_run: bool = False, detach: bool = False):
        self.config = config
        self.dry_run = dry_run
        self.detach = detach

    def run_job(self, job: NomadJob) -> None:
        cmd = ["nomad", "run"]
        # Skip detach on infra jobs to let Nomad declare them healthy before proceeding
        if self.detach and job.name not in self.config.infra_jobs:
            cmd.append("-detach")
        cmd.append(job.spec_path.name)

        self._execute(cmd, cwd=str(job.spec_path.parent))
        logger.debug(f"Started job: {job.name}")

    def stop_job(self, job: NomadJob) -> None:
        cmd = ["nomad", "stop", "-purge", job.name]
        self._execute(cmd)
        logger.debug(f"Stopped job: {job.name}")

    def is_running(self, job: NomadJob) -> bool:
        result = subprocess.run(
            ["nomad", "job", "status", "-short", job.name],
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True,
        )

        # Check whether line containing "Status" ends with "running"
        status_line = [ln for ln in result.stdout.splitlines() if "Status" in ln]
        if not status_line:
            return False
        return status_line[0].split()[-1].lower() == "running"

    def _execute(self, cmd, cwd=None):
        logger.debug(
            f"Executing command: {' '.join(cmd)}" + (f" (cwd={cwd})" if cwd else "")
        )
        if self.dry_run:
            logger.info("[DRY RUN] %s", " ".join(cmd))
            return
        try:
            subprocess.run(cmd, check=True, text=True, cwd=cwd)
        except subprocess.CalledProcessError as e:
            logger.error(f"Command failed: {' '.join(cmd)}\nError: {e.stderr}")
            raise


class JobManager:
    """Orchestrates the program flow"""

    def __init__(self, args):
        self.args = args
        self.config = Config(
            base_dir=args.base_dir,
            ignore_dirs=args.ignore_dirs,
            infra_jobs=args.infra_jobs,
        )
        self.job_registry = JobRegistry(self.config)
        self.nomad = NomadClient(self.config, dry_run=args.dry_run, detach=args.detach)

    def run(self):
        all_jobs = self.job_registry.find_jobs()
        if not all_jobs:
            logger.warning("No jobs found")
            return

        target = TargetFilter.get(self.args.target)
        targeted_jobs = target.filter(all_jobs, self.config)
        if not targeted_jobs:
            logger.warning(f"No jobs found matching target: {self.args.target}")
            return

        try:
            action = ActionHandler.get(self.args.action, self.nomad, self.config)
        except ValueError as e:
            logger.error(e)
            return

        action.handle(targeted_jobs)


def main():
    parser = argparse.ArgumentParser(
        description="Nomad job manager",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "action",
        help=f"Action to perform: {', '.join(ActionHandler._registry.keys())}",
    )
    parser.add_argument(
        "target",
        help=f"Target to operate on: {', '.join(TargetFilter._registry.keys())}, or a specific job name",
    )
    parser.add_argument(
        "--base-dir",
        default=Path.home() / "cld",
        type=Path,
        help="Base directory for discovering Nomad jobs",
    )
    parser.add_argument(
        "--ignore-dirs",
        nargs="*",
        default=["_archive", ".github", ".git"],
        help="Directories to ignore when discovering Nomad jobs",
    )
    parser.add_argument(
        "--infra-jobs",
        nargs="*",
        default=["garage", "keydb", "haproxy", "caddy", "patroni"],
        help="Critical infrastructure jobs to handle with care",
    )
    parser.add_argument("-n", "--dry-run", action="store_true", help="Dry-run mode")
    parser.add_argument(
        "-d", "--detach", action="store_true", help="Start jobs in detached mode"
    )
    parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")

    args = parser.parse_args()
    if args.verbose:
        logger.setLevel(logging.DEBUG)

    try:
        JobManager(args).run()
    except Exception as e:
        logger.error(f"Operation failed: {e}")
        exit(1)


if __name__ == "__main__":
    main()
