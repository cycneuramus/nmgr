#!/usr/bin/env python3

from __future__ import annotations

import argparse
import logging
import re
import subprocess
from abc import ABC, abstractmethod
from dataclasses import dataclass
from pathlib import Path
from typing import List

logging.basicConfig(format="%(levelname)s: %(message)s", level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    base_dir: Path
    ignore_dirs: List[str]
    infra_jobs: List[str]


@dataclass
class NomadJob:
    path: Path
    name: str
    spec: str
    configs: str


class ActionHandler(ABC):
    """Abstract base class for acting on a collection of Nomad jobs"""

    def __init__(self, nomad: NomadClient, config: Config):
        self.nomad = nomad
        self.config = config

    @abstractmethod
    def execute(self, jobs: List[NomadJob]):
        pass


class UpHandler(ActionHandler):
    """Handles the "up" action: runs a job if not running or spec has changed"""

    def execute(self, jobs: List[NomadJob]):
        for job in jobs:
            if self.nomad.is_running(job):
                logger.debug(f"Job {job.name} is already running; skipping")
                continue

            logger.debug(f"Bringing job UP: {job.name}")
            self.nomad.run_job(job)


class DownHandler(ActionHandler):
    """Handles the "down" action: stops and purges a job if running"""

    def execute(self, jobs: List[NomadJob]):
        for job in jobs:
            if not self.nomad.is_running(job):
                logger.debug(f"Job {job.name} is not running; skipping")
                continue

            logger.debug(f"Bringing job DOWN: {job.name}")
            self.nomad.stop_job(job)


class ReconcileHandler(ActionHandler):
    """Handles the "reconcile" action: restarts job if spec contains new image"""

    def execute(self, jobs: List[NomadJob]):
        for job in jobs:
            if not self.nomad.is_running(job):
                logger.debug(f"Job {job.name} is not running; skipping")
                continue

            current_image = self._get_current_image(job)
            desired_image = self._get_desired_image(job)

            logger.debug(f"Current image: {current_image}")
            logger.debug(f"Desired image: {desired_image}")

            if current_image == desired_image:
                logger.debug(f"No changes for {job.name}; skipping")
                continue

            # Skip (likely critical) infrastucture jobs by default
            if job.name in self.config.infra_jobs:
                logger.info(f"Skipping infra job: {job.name}")
                continue

            logger.info(f"Reconciling job {job.name}: image changed. Restarting...")
            self.nomad.run_job(job)

    def _get_current_image(self, job: NomadJob) -> str:
        try:
            result = subprocess.run(
                ["nomad", "job", "inspect", "-hcl", job.name],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                check=True,
            )
            return self._extract_images(result.stdout)
        except subprocess.CalledProcessError as e:
            logger.error(f"Error inspecting job {job.name}: {e.stderr}")
            return ""

    def _get_desired_image(self, job: NomadJob) -> str:
        return self._extract_images(job.spec)

    def _extract_images(self, spec: str) -> str:
        """
        Scans for lines such as 'image = "foo/bar"' or the contents of blocks such as:
            image = {
              kutt = "docker.io/kutt/kutt:v3.2.2"
              valkey = "docker.io/valkey/valkey:8.0-alpine"
            }
        """
        pattern = re.compile(r'image\s*=\s*(".*?"|\{[^}]*\})', re.DOTALL)
        images = pattern.findall(spec)
        filtered = [
            re.sub(r"\s+", " ", img.strip())
            for img in images
            if "local.image" not in img  # skip HCL variable references
        ]
        return "\n".join(filtered) if filtered else ""


class JobFilter(ABC):
    """Abstract base class for filtering Nomad jobs to act on"""

    @abstractmethod
    def filter_jobs(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        pass


class InfraFilter(JobFilter):
    """Returns infrastructure jobs, respecting their order in config.infra_jobs"""

    def filter_jobs(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        ordered = []
        for infra_name in config.infra_jobs:
            for job in jobs:
                if job.name == infra_name:
                    ordered.append(job)
        return ordered


class ServicesFilter(JobFilter):
    """Returns service (i.e. non-infrastructure) jobs"""

    def filter_jobs(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        return [job for job in jobs if job.name not in config.infra_jobs]


class AllFilter(JobFilter):
    """Returns both infra and services jobs, always ordering infra jobs first"""

    def filter_jobs(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        infra = InfraFilter().filter_jobs(jobs, config)
        services = ServicesFilter().filter_jobs(jobs, config)
        return infra + services


class NameFilter(JobFilter):
    """Returns job matching a single specific name"""

    def __init__(self, name: str):
        self.name = name

    def filter_jobs(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        return [job for job in jobs if job.name == self.name]


class ContentFilter(JobFilter):
    """Returns jobs whose spec or config files contain the specified strings"""

    def __init__(self, strings_to_match: List[str], extended_search: bool = False):
        self.strings_to_match = strings_to_match
        self.extended_search = extended_search

    def filter_jobs(self, jobs: List[NomadJob], config: Config) -> List[NomadJob]:
        matched = []
        for job in jobs:
            text = (job.configs + job.spec) if self.extended_search else job.spec
            if (
                any(string in text for string in self.strings_to_match)
                and job.name not in config.infra_jobs  # exclude infra jobs for safety
            ):
                matched.append(job)
        return matched


class Action:
    """Holds the logic for handling user-supplied action"""

    _HANDLERS = {
        "up": UpHandler,
        "down": DownHandler,
        "reconcile": ReconcileHandler,
    }

    def __init__(self, action: str, nomad: NomadClient, config: Config):
        if action not in self._HANDLERS:
            raise ValueError(f"Unknown action: {action}")
        self.handler = self._HANDLERS[action](nomad, config)

    def execute(self, jobs: List[NomadJob]):
        self.handler.execute(jobs)


class Target:
    """Holds the logic for filtering jobs based on user-supplied target"""

    _FILTERS = {
        "infra": InfraFilter(),
        "services": ServicesFilter(),
        "all": AllFilter(),
        "db": ContentFilter(["15432"], extended_search=True),
        "nas": ContentFilter(["/mnt/nas"]),
        "jfs": ContentFilter(["/mnt/jfs"]),
        "crypt": ContentFilter(["/mnt/crypt"]),
    }

    def __init__(self, target_str: str):
        self.target_str = target_str

    def get_filter(self) -> JobFilter:
        if self.target_str in self._FILTERS:
            return self._FILTERS[self.target_str]
        return NameFilter(self.target_str)


class JobStore:
    """Finds and ingests Nomad jobs along with surrounding config files"""

    _CONFIGS_PATTERN = [
        "*.env*",
        "*.toml*",
        "*.yml*",
        "*.yaml*",
        "*.sh*",
        "*.cfg*",
        "*.js*",
        "*.tpl",
    ]

    def __init__(self, config: Config):
        self.config = config

    def find_jobs(self) -> List[NomadJob]:
        jobs = []
        for path in self.config.base_dir.iterdir():
            if not path.is_dir() or path.name in self.config.ignore_dirs:
                logger.debug(f"Skipping: {path}")
                continue

            for hcl_file in path.glob("*.hcl"):
                try:
                    jobs.append(self._load_job(hcl_file))
                except ValueError as e:
                    logger.warning(f"Failed to load {hcl_file}: {e}")
        return jobs

    def _load_job(self, path: Path) -> NomadJob:
        spec = path.read_text()
        return NomadJob(
            path=path,
            name=self._extract_job_name(spec),
            spec=spec,
            configs=self._read_configs(path.parent),
        )

    def _read_configs(self, directory: Path) -> str:
        text_chunks = []
        for pattern in self._CONFIGS_PATTERN:
            for path in directory.glob(pattern):
                if path.is_file():
                    try:
                        text_chunks.append(path.read_text())
                    except Exception as e:
                        logger.warning(f"Error reading {path}: {str(e)}")
        return "\n".join(text_chunks)

    @staticmethod
    def _extract_job_name(spec: str) -> str:
        """Scans for "foo" in lines such as: 'job "foo"'"""
        match = re.search(r'job\s+"([^"]+)"', spec)
        if not match:
            raise ValueError("Missing job name in spec")
        return match.group(1)


class NomadClient:
    """Wraps interactions with the Nomad CLI"""

    def __init__(self, config: Config, dry_run: bool = False, detach: bool = False):
        self.config = config
        self.dry_run = dry_run
        self.detach = detach

    def run_job(self, job: NomadJob) -> None:
        cmd = ["nomad", "run"]
        # Skip detach on infra jobs to let Nomad declare them healthy before proceeding
        if self.detach and job.name not in self.config.infra_jobs:
            cmd.append("-detach")
        cmd.append(job.path.name)

        self._execute(cmd, cwd=str(job.path.parent))
        logger.debug(f"Started job: {job.name}")

    def stop_job(self, job: NomadJob) -> None:
        cmd = ["nomad", "stop", "-purge", job.name]
        self._execute(cmd)
        logger.debug(f"Stopped job: {job.name}")

    def is_running(self, job: NomadJob) -> bool:
        result = subprocess.run(
            ["nomad", "job", "status", "-short", job.name],
            stdout=subprocess.PIPE,
            stderr=subprocess.DEVNULL,
            text=True,
        )

        # Check whether line containing "Status" ends with "running"
        status_line = [ln for ln in result.stdout.splitlines() if "Status" in ln]
        if not status_line:
            return False
        return status_line[0].split()[-1].lower() == "running"

    def _execute(self, cmd, cwd=None):
        logger.debug(
            f"Executing command: {' '.join(cmd)}" + (f" (cwd={cwd})" if cwd else "")
        )
        if self.dry_run:
            logger.info("[DRY RUN] %s", " ".join(cmd))
            return
        try:
            subprocess.run(cmd, check=True, text=True, cwd=cwd)
        except subprocess.CalledProcessError as e:
            logger.error(f"Command failed: {' '.join(cmd)}\nError: {e.stderr}")
            raise


class JobManager:
    """Orchestrates the program flow"""

    def __init__(self, args):
        self.args = args
        self.config = Config(
            base_dir=args.base_dir,
            ignore_dirs=args.ignore_dirs,
            infra_jobs=args.infra_jobs,
        )
        self.job_store = JobStore(self.config)
        self.nomad = NomadClient(self.config, dry_run=args.dry_run, detach=args.detach)

    def run(self):
        all_jobs = self.job_store.find_jobs()
        if not all_jobs:
            logger.warning("No jobs found")
            return

        try:
            action = Action(self.args.action, self.nomad, self.config)
        except ValueError as e:
            logger.error(e)
            return

        job_filter = Target(self.args.target).get_filter()
        filtered_jobs = job_filter.filter_jobs(all_jobs, self.config)

        if not filtered_jobs:
            logger.warning(f"No jobs found matching target: {self.args.target}")
            return

        action.execute(filtered_jobs)


def main():
    parser = argparse.ArgumentParser(
        description="Nomad job manager",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "action",
        help=f"Action to perform: {', '.join(Action._HANDLERS.keys())}",
    )
    parser.add_argument(
        "target",
        help=f"Target to operate on: {', '.join(Target._FILTERS.keys())}, or a specific job name",
    )
    parser.add_argument(
        "--base-dir",
        default=Path.home() / "cld",
        type=Path,
        help="Base directory for discovering Nomad jobs",
    )
    parser.add_argument(
        "--ignore-dirs",
        nargs="*",
        default=["_archive", ".github", ".git"],
        help="Directories to ignore when discovering Nomad jobs",
    )
    parser.add_argument(
        "--infra-jobs",
        nargs="*",
        default=["garage", "keydb", "haproxy", "caddy", "patroni"],
        help="Critical infrastructure jobs to handle with care",
    )
    parser.add_argument("-n", "--dry-run", action="store_true", help="Dry-run mode")
    parser.add_argument(
        "-d", "--detach", action="store_true", help="Start jobs in detached mode"
    )
    parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")

    args = parser.parse_args()
    if args.verbose:
        logger.setLevel(logging.DEBUG)

    try:
        JobManager(args).run()
    except Exception as e:
        logger.error(f"Operation failed: {e}")
        exit(1)


if __name__ == "__main__":
    main()
